# AI Agent Development Context

This document provides essential context for AI assistants working on the Anode project.

This document provides the current work state and immediate next steps with an honest assessment of what's working versus what needs development.

**Development Workflow**: The user will typically be running the wrangler server and web client in separate tabs. If you need to check work, run a build and/or lints, tests, typechecks. If the user isn't running the dev environment, tell them how to start it at the base of the repo with pnpm.

## Project Overview

Anode is a real-time collaborative notebook system built on LiveStore, an event-sourcing based local-first data synchronization library. The project uses a monorepo structure with TypeScript and pnpm workspaces.

**Current Status**: Working prototype with collaborative editing, Python execution, and basic AI integration functional. Rich outputs need verification.

## Architecture

- **Shared Schema** (`shared/schema.ts`): LiveStore schema definitions (events, state, materializers) - TypeScript source file directly imported by all packages with full type inference
- **Web Client** (`@anode/web-client`): React-based web interface
- **Document Worker** (`@anode/docworker`): Cloudflare Worker for sync backend
- **Pyodide Runtime Agent** (`@anode/pyodide-runtime-agent`): Python execution server (manual start per notebook)

## Key Dependencies

- **LiveStore**: Event-sourcing library for local-first apps
- **Effect**: Functional programming library for TypeScript
- **React**: UI framework
- **TypeScript**: Primary language

## Current Working State

### What's Actually Working âœ…
- âœ… **LiveStore integration** - Event-sourcing with real-time collaboration working reliably
- âœ… **Python execution** - Code cells run Python via Pyodide with rich outputs (matplotlib SVG, pandas HTML, IPython.display)
- âœ… **Real-time collaboration** - Multiple users can edit notebooks simultaneously
- âœ… **Cell management** - Create, edit, move, delete cells with proper state sync
- âœ… **Rich output rendering** - Full IPython display support: matplotlib SVG, pandas HTML, colored terminal output
- âœ… **AI integration** - Full notebook context awareness, sees previous cells and their outputs
- âœ… **AI tool calling** - AI can create new cells using OpenAI function calling
- âœ… **Context inclusion controls** - Users can exclude cells from AI context with visibility toggles
- âœ… **Production deployment** - Web client and sync backend deployed to Cloudflare (Pages + Workers)
- âœ… **Authentication** - Google OAuth and fallback token system working in production
- âœ… **Mobile support** - Responsive design with mobile keyboard optimizations
- âœ… **Offline-first operation** - Works without network, syncs when connected

### What Needs Enhancement ğŸš§
- ğŸš§ **AI tool calling expansion** - AI can only create cells, needs modify/execute functions
- ğŸš§ **Automated runtime management** - Manual startup creates friction, need "Bring Your Own Compute" with API tokens
- ğŸš§ **Kernel orchestration** - Production deployment lacks automatic kernel provisioning

### Core Architecture Constraints
- `NOTEBOOK_ID = STORE_ID`: Each notebook gets its own LiveStore database
- **Event-sourced state**: All changes flow through LiveStore events
- **Reactive execution**: `executionRequested` â†’ `executionAssigned` â†’ `executionStarted` â†’ `executionCompleted` events, materialized table is an execution queue
- **Direct TypeScript schema**: No build step, imports work across packages
- **Session-based runtimes**: Each runtime restart gets unique `sessionId`
- **One kernel per notebook**: Each notebook has exactly one active kernel at a time

### Kernel-Notebook Relationship

**One Kernel Per Notebook**: Each notebook should have exactly one active kernel at any time. Multiple kernels on the same notebook should only occur during transition periods (kernel restart/handoff).

**Kernel Lifecycle**:
- Notebook created â†’ No kernel (user must start one)
- User starts kernel â†’ Becomes the sole kernel for that notebook
- Kernel crashes/stops â†’ Notebook has no kernel until user starts new one
- Kernel restart â†’ Brief overlap during handoff, then old kernel terminates

**Not Yet Implemented**: Automatic kernel orchestration, graceful handoffs, kernel health monitoring. Currently manual kernel startup creates potential for multiple kernels during transitions.

## Development Commands

```bash
# Setup
pnpm install  # Automatically creates package .env files with defaults

# In separate tabs run
## Tab 1:
pnpm dev:web-only
## Tab 2:
pnpm dev:sync-only

# Start runtime (get command from notebook UI)
# Get runtime command from notebook UI, then:
NOTEBOOK_ID=notebook-id-from-ui pnpm dev:runtime

# Utilities
pnpm reset-storage  # Clear all local storage

# Package caching (Node.js only)
pnpm cache:warm-up     # Pre-load essential packages for faster startup
pnpm cache:stats       # Show cache statistics
pnpm cache:list        # List cached packages
pnpm cache:clear       # Clear package cache
```

## Immediate Priorities

**Priority Focus**: Verify core functionality works, then remove friction

### Phase 1: Enhanced AI & Runtime Management (Next 2 weeks)
- **AI Function Calling Expansion** - AI can modify cell content and execute code (beyond just creating cells)
- **User-Attributed Kernels** - API token system for "Bring Your Own Compute" runtime agents
- **Automated Runtime Management** - Remove manual `NOTEBOOK_ID=xyz pnpm dev:runtime` friction
- **AI Tool Calling Confirmation** - User confirmation flows for AI-initiated actions

**Priority Focus**: Verify core functionality works, then remove friction

**Next Major Feature**: User-attributed kernel system with API tokens to enable "Bring Your Own Compute" - users get API tokens to run standalone runtime agents, removing kernel orchestration complexity while enabling production-scale compute.

### Phase 2: Advanced Features (Next 2-3 months)
- **SQL Cell Implementation** - Database connections and query results
- **Interactive Widgets** - IPython widgets support for collaborative elements
- **Code Completions** - LSP + kernel-based suggestions
- **Kernel Orchestration** - Production automatic kernel provisioning

## Important Considerations

### Schema Design
- **Direct TypeScript imports**: `shared/schema.ts` provides zero-build-step imports with type inference across all packages

### âš ï¸ CRITICAL: Materializer Determinism Requirements

**NEVER use `ctx.query()` in materializers** - This was the root cause of runtime restart bug #34.

LiveStore requires all materializers to be **pure functions without side effects**. Any data needed by a materializer must be passed via the event payload, not looked up during materialization.

**What caused the bug:**
```typescript
// âŒ WRONG - This causes LiveStore.UnexpectedError materializer hash mismatch
"v1.ExecutionCompleted": ({ queueId }, ctx) => {
  const queueEntries = ctx.query(
    tables.executionQueue.select().where({ id: queueId }).limit(1)
  );
  // ... rest of materializer
}
```

**Correct approach:**
```typescript
// âœ… CORRECT - All needed data in event payload
"v1.ExecutionCompleted": ({ queueId, cellId, status }) => [
  tables.executionQueue.update({
    status: status === "success" ? "completed" : "failed"
  }).where({ id: queueId }),
  tables.cells.update({
    executionState: status === "success" ? "completed" : "error"
  }).where({ id: cellId }),
]
```

**Fixed commits for reference:**
- `6e0fb4f`: Fixed ExecutionCompleted/ExecutionCancelled materializers
- `a1bf20d`: Fixed ExecutionStarted materializer

**Rule**: If you need data in a materializer, add it to the event schema and pass it when committing the event. Materializers must be deterministic and reproducible.

### Recent Critical Fixes (June 2025)

**Runtime Restart Bug (#34) - RESOLVED** âœ…

The project recently resolved a major stability issue where 3rd+ runtime sessions would fail to receive work assignments due to LiveStore materializer hash mismatches. This was caused by non-deterministic materializers using `ctx.query()` calls.

**What was broken:**
- ExecutionCompleted, ExecutionCancelled, and ExecutionStarted materializers were using `ctx.query()`
- This made them non-deterministic, causing LiveStore to shut down with "UnexpectedError materializer hash mismatch"
- Runtime restarts would accumulate terminated sessions and eventually fail

**How it was fixed (commits 6e0fb4f and a1bf20d):**
1. **Added cellId to event schemas**: ExecutionCompleted, ExecutionCancelled, ExecutionStarted now include `cellId` in payload
2. **Removed all ctx.query() calls**: Materializers now receive all needed data via event payload
3. **Updated all event commits**: All places that commit these events now pass `cellId` explicitly
4. **Made materializers pure functions**: No side effects, deterministic output for same input

**Impact:** Runtime sessions are now reliable across multiple restarts, enabling future automated runtime management.

**For Future Development:**
- Always check that new materializers are pure functions
- Never use `ctx.query()` in materializers - pass data via event payload
- Reference these commits when adding new execution-related events
- Test runtime restart scenarios when modifying execution flow

### Local-First Architecture
- All data operations happen locally first
- Events synced across clients via document worker
- SQLite provides local reactive state per notebook
- Network connectivity optional

### Code Style
- Prefer functional programming patterns (Effect library)
- Event sourcing over direct state mutations
- Reactive queries over imperative data fetching
- TypeScript strict mode enabled

## File Structure

```
anode/
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ schema.ts                    # LiveStore schema - TypeScript source directly imported by all packages
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ web-client/                  # React web application (@anode/web-client)
â”‚   â”‚   â”œâ”€â”€ src/components/notebook/ # Notebook interface components
â”‚   â”‚   â”œâ”€â”€ dist/                    # Built assets for Cloudflare Pages deployment
â”‚   â”‚   â””â”€â”€ package.json             # Vite + React + LiveStore dependencies
â”‚   â”œâ”€â”€ docworker/                   # Cloudflare Worker sync backend (@anode/docworker)
â”‚   â”‚   â”œâ”€â”€ src/index.ts             # Worker entry point with LiveStore sync
â”‚   â”‚   â”œâ”€â”€ wrangler.toml            # Cloudflare Worker configuration
â”‚   â”‚   â””â”€â”€ package.json             # Minimal Worker dependencies
â”‚   â””â”€â”€ pyodide-runtime-agent/       # Python runtime server (@anode/pyodide-runtime-agent)
â”‚       â”œâ”€â”€ src/                     # TypeScript runtime implementation
â”‚       â”‚   â”œâ”€â”€ runtime-agent.ts     # Main execution coordinator
â”‚       â”‚   â”œâ”€â”€ pyodide-kernel.ts    # Python execution via Pyodide
â”‚       â”‚   â””â”€â”€ openai-client.ts     # AI integration
â”‚       â””â”€â”€ package.json             # Node.js runtime dependencies
â”œâ”€â”€ docs/                            # Comprehensive documentation (11 files)
â”‚   â”œâ”€â”€ README.md                    # Documentation index and navigation
â”‚   â”œâ”€â”€ runtime-agent-architecture.md # Core system design
â”‚   â”œâ”€â”€ ai-features.md               # AI integration setup and capabilities
â”‚   â”œâ”€â”€ display-system.md            # IPython display system architecture
â”‚   â”œâ”€â”€ display-examples.md          # Rich output usage examples
â”‚   â”œâ”€â”€ ui-design.md                 # Interface design guidelines
â”‚   â”œâ”€â”€ TESTING.md                   # Testing strategy and current gaps
â”‚   â”œâ”€â”€ ai-context-visibility.md     # Context control implementation
â”‚   â”œâ”€â”€ pyodide_cache.md             # Package caching system
â”‚   â”œâ”€â”€ ui-enhancements-demo.md      # UI improvement showcase
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md    # Technical implementation details
â”‚   â””â”€â”€ proposals/                   # Architecture proposals (6 files)
â”‚       â”œâ”€â”€ ai-tool-calling.md       # OpenAI function calling architecture
â”‚       â”œâ”€â”€ ai-context-controls.md   # Context visibility system
â”‚       â”œâ”€â”€ completion-system.md     # Code completion design
â”‚       â”œâ”€â”€ kernel-management.md     # Runtime automation
â”‚       â”œâ”€â”€ mcp-integration.md       # Model Context Protocol analysis
â”‚       â””â”€â”€ updateable-outputs.md    # Jupyter compatibility
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ ai-context-demo.md           # AI context demonstration
â”œâ”€â”€ test/                            # Test suite
â”‚   â”œâ”€â”€ README.md                    # Test documentation
â”‚   â”œâ”€â”€ basic.test.ts                # Core functionality tests
â”‚   â”œâ”€â”€ edge-cases.test.ts           # Edge case handling
â”‚   â”œâ”€â”€ integration/                 # Integration test suite
â”‚   â””â”€â”€ fixtures/                    # Test data and mocks
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup.js                     # Environment setup automation
â”œâ”€â”€ .github/                         # GitHub configuration
â”œâ”€â”€ AGENTS.md                        # AI agent development context (this file)
â”œâ”€â”€ ROADMAP.md                       # Long-term vision and milestones
â”œâ”€â”€ DEPLOYMENT.md                    # Cloudflare deployment guide
â”œâ”€â”€ CONTRIBUTING.md                  # Contribution guidelines
â”œâ”€â”€ README.md                        # Project overview and quick start
â”œâ”€â”€ package.json                     # Root workspace configuration and scripts
â”œâ”€â”€ pnpm-workspace.yaml              # Workspace definitions
â”œâ”€â”€ vitest.config.ts                 # Test runner configuration
â””â”€â”€ tsconfig.json                    # TypeScript project configuration
```

**Deployment Architecture (Cloudflare):**
- **Pages**: Web client deployed to `https://anode.pages.dev`
- **Workers**: Sync backend deployed to `https://anode-docworker.rgbkrk.workers.dev`
- **D1**: Database for production data persistence
- **Secrets**: Authentication tokens and API keys managed via Cloudflare dashboard

## Notes for AI Assistants

**Current Status - Production Deployment Working**
- **LiveStore foundation** - Real-time collaborative editing deployed and stable
- **Full Python execution** - Rich outputs working (matplotlib, pandas, IPython.display)
- **Complete AI integration** - Full notebook context awareness, can create cells
- **Production deployment** - Cloudflare Pages + Workers with authentication
- **Direct TypeScript schema** - No build complexity across packages

### Key Development Insights
- **Production deployment achieved** - Full stack working on Cloudflare infrastructure
- **Rich outputs working** - Complete IPython display compatibility with matplotlib, pandas
- **AI context awareness complete** - AI sees full notebook state including outputs
- **Reactive architecture** eliminates polling delays for execution
- **Manual runtime startup** remains the main friction point for users

### Immediate Technical Goals
- **AI tool calling expansion** - Enable AI to modify content and execute code (beyond creating cells)
- **User-attributed kernels** - API token system for "Bring Your Own Compute"
- **Automated kernel orchestration** - Production runtime provisioning

### Communication Style
- Use authentic developer voice - uncertainty is fine, just be explicit
- Be honest about current prototype status while preserving the collaborative vision
- Focus on proving core functionality works before claiming production readiness
- Emphasize the solid LiveStore foundation and collaborative advantages
- Clarity is essential. Being concise moreso.

## Development Workflow Notes

**User Environment**: The user will typically have:
- Web client running in one tab (`pnpm dev`)
- Wrangler server running in another tab
- Manual runtime startup as needed (`NOTEBOOK_ID=xyz pnpm dev:runtime`)

**Checking Work**: If you need to verify changes:
```bash
# Build and check for issues
pnpm build           # Build all packages
pnpm lint            # Check code style
pnpm test            # Run test suite
pnpm type-check      # TypeScript validation
```

**If User Isn't Running Dev Environment**:
Tell them to start at the base of the repo:
```bash
# Setup environment
pnpm install         # Automatically creates package .env files with defaults

# In separate tabs run
## Tab 1:
pnpm dev:web-only
## Tab 2:
pnpm dev:sync-only

# Warm up package cache for faster Python execution (recommended)
pnpm cache:warm-up   # Pre-loads numpy, pandas, matplotlib, requests, etc.

# In separate terminal, get runtime command from notebook UI
# Then run: NOTEBOOK_ID=notebook-id-from-ui pnpm dev:runtime
```

## Important Development Notes

**âš ï¸ CRITICAL: Do NOT use `ctx.query()` in materializers.** This causes LiveStore materializer hash mismatches and kernel restart failures (see bug #34 - RESOLVED in commits 6e0fb4f and a1bf20d). All materializers must be pure functions with all needed data passed via event payload.

**Testing is Critical**: Many claims about functionality need verification through proper integration tests. Core features exist but integration testing is minimal.

**AI Tool Calling**: The next major enhancement is enabling AI to actively participate in notebook development through function calling - creating cells, modifying content, and executing code.

**Context Control**: Users need granular control over what context AI sees, especially in large notebooks where token limits matter.

**Kernel Management**: Manual kernel startup (copying command from UI) creates user friction and should be a high priority to fix.

**Current Reality**: This is a working system deployed to production with core Jupyter functionality. Rich outputs, real-time collaboration, and AI integration are functional. Main gap is automated runtime management.
